i want a localhost based app using flask, html, css for running llms locally which have to provide a ui over ollama. i run locally using ollama. this should properly see all the models that ive downloaded and show that in the UI. Also, i should be able to save multiple default prompts, which i should be able to reuse using a click. make teh UI look great


features needed
- show gpu, cpu usage
- show ram, vram usage (it getting filled up as we load models)
- stream the results
- the UI should support codeblocks(with python color for LSP and all)
- UI should support rendering tables
- refresh talk and clear context button at top right
- store conversation history
- ability to edit/ delete saved prompts


- i want the gpucpu info in 2 boxes. 
    - first shows cpu % and RAM in numbers(7.6/16GB)
    - second shows gpu% and VRAM in numbers(1.2/4GB)
    - this should update very fast (every 0.25 seconds)

- the history is saving every talk and back in full conversation as separate history. one conversation needs to be in one history block only
- add copy button for codeblocks
- When you are loading any model, say loaing model. 
- tell the tokens per second for conversation as small text and total token per conv
- add model page which contains details for model such as model params, size, company, etc. 

- make sure the vram for gpu is working
- add a restart server option, which pkills ollama and starts the server

- add a little bit of spacebetween %usage and ram for both cpu and gpu - they are coinciding now
- add a favourite option, which lets me favourite models - these models appear first in model selector
- some models think. I want this thinking to appear in another box while thinking happens. This box is  always in condensed mode and will reveal only after the user pressing it

- the stop generating button doesnt stop genereating instantly, pls fix
- change clear context to new chat(it should also set teh token usage to 0)
now give me whole code, dont miss out anyything

one more modification, can u do it so that i can add whatever template i want for the model card and add additional information to it. these information should come up in the model card. make sure not to remove any other code or anything else. add a separate file to design the model card template. 
so the working of model card will be like when it sees a model listed in ollama, u look at model card to see if additional info is in it. if it is, the additional info is also shown
dont break or remove anything, pls