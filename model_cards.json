{
  "deepseek-r1:32b": {
    "description": "Distilled version of DeepSeek R1 for reasoning tasks.",
    "tags": ["thinking", "complex reasoning"],
    "icon": "fa-brain",
    "color": "border-blue-400"
  },
  "gemma3:27b": {
    "description": "Superfast google model, made for chat and general purpose tasks.",
    "tags": ["Fast", "Chat"],
    "icon": "fa-gem",
    "color": "border-blue-400",
    "speed": "10" 
  },
  "gpt-oss:latest": {
    "description": "Close to GPT4 performance",
    "tags": ["thinking", "Chat"],
    "icon": "fa-robot",
    "color": "border-blue-400"
  },
  "qwen3-coder:30b": {
    "description": "State-of-the-art coding model for its size.",
    "tags": ["coding"],
    "icon": "fa-code",
    "color": "border-blue-400"
  },
  "devstral-small-2:latest": {
    "description": "A highly efficient Mistral-based model fine-tuned for development workflows.",
    "tags": ["fast", "coding"],
    "icon": "fa-wind",
    "color": "border-blue-400"
  },
  "gemma3:270m": {
    "description": "Ultra-lightweight Gemma variant.",
    "tags": ["fast"],
    "icon": "fa-mobile-screen",
    "color": "border-blue-400"
  },
  "gemma3n:e4b": {
    "description": "Experimental edge-optimized version of the Gemma architecture.",
    "tags": ["experimental", "fast"],
    "icon": "fa-flask",
    "color": "border-blue-400"
  },
  "llama2-uncensored:7b": {
    "description": "Llama 2 7B with refusal mechanisms removed for unrestricted conversation.",
    "tags": ["uncensored", "talks too little", "chat"],
    "icon": "fa-unlock",
    "color": "border-blue-400"
  },
  "llama3.2:3b": {
    "description": "Meta's lightweight Llama 3.2, optimized for speed and low latency.",
    "tags": [ "fast"],
    "icon": "fa-layer-group",
    "color": "border-blue-400"
  },
  "qwen3:0.6b": {
    "description": "Nano-sized Qwen model. Extremely fast, suitable for simple tasks.",
    "tags": ["light", "Speed"],
    "icon": "fa-feather",
    "color": "border-blue-400"
  }
}